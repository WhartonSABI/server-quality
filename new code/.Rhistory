geom_line(size = 1) +
scale_color_manual(values = c("blue", rainbow(n_max))) +  # Set custom colors
labs(title = paste("Mother Wavelet and H_n(t) for n = 1 to", n_max),
x = "t", y = "H(t)", color = "Wavelet") +
theme_minimal() +
theme(legend.position = "top", legend.box = "horizontal", legend.box.spacing = unit(0.5, "cm"))
# Print the plot
print(p)
}
# Example: Plot H_n(t) for n from 1 to 8 with different colors
plot_wavelets(8)
# Example: Plot H_n(t) for n from 1 to 8 with different colors
plot_wavelets(4)
## clear environment (if desired)
rm(list=ls())
library(ggplot2)
library(dplyr)
# Define the "mother wavelet" H(t)
H <- function(t) {
if (t >= 0 && t < 0.5) {
return(1)
} else if (t >= 0.5 && t <= 1) {
return(-1)
} else {
return(0)
}
}
# Define the sequence of functions H_n(t)
H_n <- function(t, j, k) {
return(2^(j/2) * H(2^j * t - k))
}
# Plotting function using ggplot2
plot_wavelets <- function(n_max) {
t_vals <- seq(0, 1, length.out = 1000)
# Set up data for the plot
data_list <- list()
# Add the mother wavelet to the data
mother_wavelet <- data.frame(t = t_vals, H_t = sapply(t_vals, H), wavelet = "Mother Wavelet")
data_list[[1]] <- mother_wavelet
# Add the wavelets H_n(t) to the data
for (n in 1:n_max) {
j <- floor(log2(n))
k <- n - 2^j
wavelet_vals <- sapply(t_vals, H_n, j = j, k = k)
wavelet_data <- data.frame(t = t_vals, H_t = wavelet_vals, wavelet = paste("H_", n, "(t)", sep = ""))
data_list[[n + 1]] <- wavelet_data
}
# Combine the data into one data frame
all_data <- bind_rows(data_list)
# Create the ggplot
p <- ggplot(all_data, aes(x = t, y = H_t, color = wavelet, linetype = wavelet)) +
geom_line(size = 1) +
scale_color_manual(values = c("blue", rainbow(n_max))) +  # Set custom colors
labs(title = paste("Mother Wavelet and H_n(t) for n = 1 to", n_max),
x = "t", y = "H(t)", color = "Wavelet") +
theme_minimal() +
theme(legend.position = "top", legend.box = "horizontal", legend.box.spacing = unit(0.5, "cm"))
# Print the plot
print(p)
}
# Example: Plot H_n(t) for n from 1 to 8 with different colors
plot_wavelets(7)
# Define the triangle function Delta(t)
Delta <- function(t) {
if (t >= 0 && t < 0.5) {
return(2 * t)
} else if (t >= 0.5 && t <= 1) {
return(2 * (1 - t))
} else {
return(0)
}
}
# Define the sequence of functions Delta_n(t)
Delta_n <- function(t, j, k) {
ifelse(t==0, return(t), return(Delta(2^j * t - k)))
}
# Plotting function using ggplot2
plot_triangle_wavelets <- function(n_max) {
t_vals <- seq(0, 1, length.out = 1000)
# Set up data for the plot
data_list <- list()
# Add the mother wavelet (Delta(t)) to the data--i think mother wavelet is same as delta_1
mother_wavelet <- data.frame(t = t_vals, Delta_t = sapply(t_vals, Delta), wavelet = "Mother Wavelet")
data_list[[1]] <- mother_wavelet
# Add the functions Delta_n(t) for n = 1 to n_max
for (n in 1:n_max) {
j <- floor(log2(n))
k <- n - 2^j
wavelet_vals <- sapply(t_vals, Delta_n, j = j, k = k)
wavelet_data <- data.frame(t = t_vals, Delta_t = wavelet_vals, wavelet = paste("Delta_", n, "(t)", sep = ""))
data_list[[n + 2]] <- wavelet_data
}
# Combine the data into one data frame
all_data <- bind_rows(data_list)
# Create the ggplot
p <- ggplot(all_data, aes(x = t, y = Delta_t, color = wavelet, linetype = wavelet)) +
geom_line(size = 1) +
scale_color_manual(values = c("blue", rainbow(n_max + 1))) +  # Set custom colors (blue for mother wavelet)
labs(title = paste("Delta_n(t) and Mother Wavelet for n = 0 to", n_max),
x = "t", y = "Delta(t)", color = "Wavelet") +
theme_minimal() +
theme(legend.position = "top", legend.box = "horizontal", legend.box.spacing = unit(0.5, "cm"))
# Print the plot
print(p)
}
# Example: Plot Delta_n(t) for n from 0 to 7 with different colors and including the mother wavelet
plot_triangle_wavelets(7)
# Define lambda_n calculation
lambda_n <- function(n) {
if (n == 0) {
return(1)
} else {
j <- floor(log2(n))  # This corresponds to the j value for n = 2^j + k
return(1/2 * 2^(-j/2))
}
}
# Define X_t as the sum of terms for each t
X_t <- function(t, n_max) {
Xt_sum <- 0
for (n in 0:n_max) {
j <- floor(log2(n))
k <- n - 2^j
lambda_n_value <- lambda_n(n)
Z_n <- rnorm(1)  # Generating standard normal random variable
Xt_sum <- Xt_sum + lambda_n_value * Z_n * Delta_n(t, j, k)
}
return(Xt_sum)
}
# Plotting function
plot_X_t <- function(n_max) {
t_vals <- seq(0, 1, length.out = 1000)
# Compute X_t for each t value
Xt_vals <- sapply(t_vals, X_t, n_max = n_max)
# Create the data frame for ggplot
data <- data.frame(t = t_vals, X_t = Xt_vals)
# Create the ggplot
p <- ggplot(data, aes(x = t, y = X_t)) +
geom_line(size = 1) +
labs(title = paste("X_t for n = 0 to", n_max),
x = "t", y = "X_t") +
theme_minimal()
# Print the plot
print(p)
}
# Example: Plot X_t for n from 0 to 8
plot_X_t(7)
# Plotting function
plot_X_t <- function(n_max) {
t_vals <- seq(0, 1, length.out = 16)
# Compute X_t for each t value
Xt_vals <- sapply(t_vals, X_t, n_max = n_max)
# Create the data frame for ggplot
data <- data.frame(t = t_vals, X_t = Xt_vals)
# Create the ggplot
p <- ggplot(data, aes(x = t, y = X_t)) +
geom_line(size = 1) +
labs(title = paste("X_t for n = 0 to", n_max),
x = "t", y = "X_t") +
theme_minimal()
# Print the plot
print(p)
}
# Example: Plot X_t for n from 0 to 8
plot_X_t(7)
# Plotting function
plot_X_t <- function(n_max) {
t_vals <- seq(0, 1, length.out = 1000)
# Compute X_t for each t value
Xt_vals <- sapply(t_vals, X_t, n_max = n_max)
# Create the data frame for ggplot
data <- data.frame(t = t_vals, X_t = Xt_vals)
# Create the ggplot
p <- ggplot(data, aes(x = t, y = X_t)) +
geom_line(size = 1) +
labs(title = paste("X_t for n = 0 to", n_max),
x = "t", y = "X_t") +
theme_minimal()
# Print the plot
print(p)
}
# Example: Plot X_t for n from 0 to 8
plot_X_t(7)
# Plotting function using ggplot2
plot_wavelets <- function(n_max) {
t_vals <- seq(0, 1, length.out = 1000)
# Set up data for the plot
data_list <- list()
# Add the mother wavelet to the data
mother_wavelet <- data.frame(t = t_vals, H_t = sapply(t_vals, H), wavelet = "Mother Wavelet")
data_list[[1]] <- mother_wavelet
# Add the wavelets H_n(t) to the data
for (n in 1:n_max) {
j <- floor(log2(n))
k <- n - 2^j
wavelet_vals <- sapply(t_vals, H_n, j = j, k = k)
wavelet_data <- data.frame(t = t_vals, H_t = wavelet_vals, wavelet = paste("H_", n, "(t)", sep = ""))
data_list[[n + 1]] <- wavelet_data
}
# Combine the data into one data frame
all_data <- bind_rows(data_list)
# Create the ggplot
p <- ggplot(all_data, aes(x = t, y = H_t, color = wavelet, linetype = wavelet)) +
geom_line(size = 1) +
scale_color_manual(values = c("blue", rainbow(n_max))) +  # Set custom colors
labs(title = paste("Mother Wavelet and H_n(t) for n = 1 to", n_max),
x = "t", y = "H(t)", color = "Wavelet") +
theme_minimal() +
theme(legend.position = "top", legend.box = "horizontal", legend.box.spacing = unit(0.5, "cm"))
# Print the plot
print(p)
}
# Example: Plot H_n(t) for n from 1 to 8 with different colors
plot_wavelets(3)
p_be <- 11 / 21
z <- qnorm(0.975)
p_values <- seq(p_BE + 1e-4, 1, length.out = 100)
p_values <- seq(p_be + 1e-4, 1, length.out = 100)
n_required <- numeric(length(p_values))
for (i in 1:length(p_values)) {
p <- p_values[i]
num <- z * sqrt(p * (1 - p))
denom <- p - p_BE
n_required[i] <- ceiling((num / denom)^2)
}
for (i in 1:length(p_values)) {
p <- p_values[i]
num <- z * sqrt(p * (1 - p))
denom <- p - p_be
n_required[i] <- ceiling((num / denom)^2)
}
# dataframe for lpotting
plot_data <- data.frame(
p = p_values,
n = n_required
)
ggplot(plot_data, aes(x = p, y = n)) +
geom_line(color = "blue", size = 1) +
geom_vline(xintercept = p_be, linetype = "dashed", color = "red") +
labs(title = "Number of Bets Needed for 95% Confidence of Profitability",
x = "True Success Rate (p)",
y = "Minimum Bets Needed (n)") +
theme_minimal()
# install.packages(c("ggplot2", "tidyverse"))
library(ggplot2)
library(tidyverse)
library(broom)
ggplot(plot_data, aes(x = p, y = n)) +
geom_line(color = "blue", size = 1) +
geom_vline(xintercept = p_be, linetype = "dashed", color = "red") +
labs(title = "Number of Bets Needed for 95% Confidence of Profitability",
x = "True Success Rate (p)",
y = "Minimum Bets Needed (n)") +
theme_minimal()
n_required
View(plot_data)
# --- Clear Environment & Load Libraries ---
rm(list = ls())
library(tidyverse)
library(data.table)
# --- Load Data ---
subset_m <- fread("out_data/scaled/wimbledon_subset_m_training.csv")
names(subset_m)
setwd("C:/UPenn/tennis_wsabi/new code")
# --- Clear Environment & Load Libraries ---
rm(list = ls())
library(tidyverse)
library(data.table)
# --- Load Data ---
subset_m <- fread("out_data/scaled/wimbledon_subset_m_training.csv")
names(subset_m)
# --- Step 1: Filter relevant rows ---
# ServeNumber == 1 means first serve was in, ServeNumber == 2 means it was out
# We only care about first serve attempts
df <- subset_m %>%
filter(ServeNumber %in% c(1, 2)) %>%
mutate(first_serve_in = ifelse(ServeNumber == 1, 1, 0))
# --- Step 2: Compute first serve stats per match per server ---
match_player_stats <- df %>%
group_by(match_id, ServerName) %>%
summarise(
n_points = n(),
n_first_in = sum(first_serve_in),
.groups = "drop"
) %>%
mutate(first_in_rate = n_first_in / n_points)
# --- Step 3: Compute per-player averages across matches ---
player_summary <- match_player_stats %>%
group_by(ServerName) %>%
summarise(
n_matches = n(),
avg_first_in_rate = mean(first_in_rate),
.groups = "drop"
)
# --- Step 4: Compute weighted average across all players ---
overall_weighted_avg <- player_summary %>%
mutate(weight = n_matches / sum(n_matches)) %>%
summarise(prob_first_serve_in = sum(avg_first_in_rate * weight)) %>%
pull(prob_first_serve_in)
overall_weighted_avg
# --- Most common ServeWidth and ServeDepth ---
mode_width <- df %>% count(ServeWidth) %>% arrange(desc(n)) %>% slice(1) %>% pull(ServeWidth)
mode_depth <- df %>% count(ServeDepth) %>% arrange(desc(n)) %>% slice(1) %>% pull(ServeDepth)
# --- Modeling datasets ---
first_serve_df <- df %>% filter(ServeNumber == 1)
second_serve_df <- df %>% filter(ServeNumber == 2)
# --- Fit logistic models ---
predictors <- c("Speed_MPH_z", "ServeWidth", )
rm(list = ls())
library(tidyverse)
library(data.table)
# --- Load Data ---
subset_m <- fread("out_data/scaled/wimbledon_subset_m_training.csv")
names(subset_m)
# --- Step 1: Filter relevant rows ---
# ServeNumber == 1 means first serve was in, ServeNumber == 2 means it was out
# We only care about first serve attempts
df <- subset_m %>%
filter(ServeNumber %in% c(1, 2)) %>%
mutate(first_serve_in = ifelse(ServeNumber == 1, 1, 0))
# --- Step 2: Compute first serve stats per match per server ---
match_player_stats <- df %>%
group_by(match_id, ServerName) %>%
summarise(
n_points = n(),
n_first_in = sum(first_serve_in),
.groups = "drop"
) %>%
mutate(first_in_rate = n_first_in / n_points)
# --- Step 3: Compute per-player averages across matches ---
player_summary <- match_player_stats %>%
group_by(ServerName) %>%
summarise(
n_matches = n(),
avg_first_in_rate = mean(first_in_rate),
.groups = "drop"
)
# --- Step 4: Compute weighted average across all players ---
overall_weighted_avg <- player_summary %>%
mutate(weight = n_matches / sum(n_matches)) %>%
summarise(prob_first_serve_in = sum(avg_first_in_rate * weight)) %>%
pull(prob_first_serve_in)
overall_weighted_avg
# --- Most common ServeWidth and ServeDepth ---
mode_width <- df %>% count(ServeWidth) %>% arrange(desc(n)) %>% slice(1) %>% pull(ServeWidth)
mode_depth <- df %>% count(ServeDepth) %>% arrange(desc(n)) %>% slice(1) %>% pull(ServeDepth)
# --- Modeling datasets ---
first_serve_df <- df %>% filter(ServeNumber == 1)
second_serve_df <- df %>% filter(ServeNumber == 2)
# --- Fit logistic models ---
predictors <- c("Speed_MPH_z", "ServeWidth", "ServeDepth", "importance_z", "df_pct_server_z", "p_server_beats_returner_z")
formula <- as.formula(paste("serving_player_won ~", paste(predictors, collapse = " + ")))
model_first <- glm(formula, data = first_serve_df, family = "binomial")
model_second <- glm(formula, data = second_serve_df, family = "binomial")
# --- Fixed values for other predictors (use median z-values) ---
median_vals <- df %>%
summarise(across(all_of(predictors[4:6]), median, na.rm = TRUE))  # skip speed_ratio_z for now
View(median_vals)
# --- Create speed range and compute z-scores ---
speed_seq <- seq(80, 135, by = 1)
speed_mean <- mean(df$Speed_MPH, na.rm = TRUE)
speed_sd <- sd(df$Speed_MPH, na.rm = TRUE)
speed_z <- (speed_seq - speed_mean) / speed_sd
# --- Construct data for prediction ---
grid_data <- tibble(
Speed_MPH = speed_seq,
speed_ratio_z = (speed_seq / mean(df$Speed_MPH, na.rm = TRUE) - 1),  # use ratio to player average
importance_z = median_vals$importance_z,
df_pct_server_z = median_vals$df_pct_server_z,
p_server_beats_returner_z = median_vals$p_server_beats_returner_z,
ServeWidth = mode_width,
ServeDepth = mode_depth
)
# --- Predict win probabilities ---
p_first_in <- 0.6481901
grid_data <- grid_data %>%
mutate(
p_win_first = predict(model_first, newdata = ., type = "response"),
p_win_second = predict(model_second, newdata = ., type = "response"),
p_win_total = p_win_first * p_first_in + p_win_second * (1 - p_first_in)
)
# --- Create speed range and compute z-scores ---
speed_seq <- seq(80, 135, by = 1)
speed_mean <- mean(df$Speed_MPH_z, na.rm = TRUE)
speed_sd <- sd(df$Speed_MPH_z, na.rm = TRUE)
speed_z <- (speed_seq - speed_mean) / speed_sd
# --- Construct data for prediction ---
grid_data <- tibble(
Speed_MPH_z = speed_seq,
speed_ratio_z = (speed_seq / mean(df$Speed_MPH, na.rm = TRUE) - 1),  # use ratio to player average
importance_z = median_vals$importance_z,
df_pct_server_z = median_vals$df_pct_server_z,
p_server_beats_returner_z = median_vals$p_server_beats_returner_z,
ServeWidth = mode_width,
ServeDepth = mode_depth
)
# --- Predict win probabilities ---
p_first_in <- 0.6481901
grid_data <- grid_data %>%
mutate(
p_win_first = predict(model_first, newdata = ., type = "response"),
p_win_second = predict(model_second, newdata = ., type = "response"),
p_win_total = p_win_first * p_first_in + p_win_second * (1 - p_first_in)
)
# --- Find optimal serve speed ---
optimal_row <- grid_data %>% filter(p_win_total == max(p_win_total)) %>% slice(1)
# --- Plot ---
library(ggplot2)
ggplot(grid_data, aes(x = Speed_MPH, y = p_win_total)) +
geom_line(size = 1.2, color = "blue") +
geom_point(data = optimal_row, aes(x = Speed_MPH, y = p_win_total), color = "red", size = 3) +
geom_text(
data = optimal_row,
aes(x = Speed_MPH, y = p_win_total, label = sprintf("Optimal: %.0f MPH", Speed_MPH)),
vjust = -1.2, hjust = 0.5, size = 4, color = "red"
) +
labs(
title = "Serve Speed vs. Overall Point Win Probability",
x = "Serve Speed (MPH)",
y = "P(win)",
caption = "Holding serve placement, importance, df_pct, and opponent quality constant"
) +
theme_minimal()
# --- Fit logistic models ---
predictors <- c("Speed_MPH", "ServeWidth", "ServeDepth", "importance_z", "df_pct_server_z", "p_server_beats_returner_z")
formula <- as.formula(paste("serving_player_won ~", paste(predictors, collapse = " + ")))
model_first <- glm(formula, data = first_serve_df, family = "binomial")
model_second <- glm(formula, data = second_serve_df, family = "binomial")
# --- Fixed values for other predictors (use median z-values) ---
median_vals <- df %>%
summarise(across(all_of(predictors[4:6]), median, na.rm = TRUE))  # skip speed_ratio_z for now
# --- Create speed range and compute z-scores ---
speed_seq <- seq(80, 135, by = 1)
speed_mean <- mean(df$Speed_MPH, na.rm = TRUE)
speed_sd <- sd(df$Speed_MPH, na.rm = TRUE)
speed_z <- (speed_seq - speed_mean) / speed_sd
# --- Construct data for prediction ---
grid_data <- tibble(
Speed_MPH = speed_seq,
speed_ratio_z = (speed_seq / mean(df$Speed_MPH, na.rm = TRUE) - 1),  # use ratio to player average
importance_z = median_vals$importance_z,
df_pct_server_z = median_vals$df_pct_server_z,
p_server_beats_returner_z = median_vals$p_server_beats_returner_z,
ServeWidth = mode_width,
ServeDepth = mode_depth
)
# --- Predict win probabilities ---
p_first_in <- 0.6481901
grid_data <- grid_data %>%
mutate(
p_win_first = predict(model_first, newdata = ., type = "response"),
p_win_second = predict(model_second, newdata = ., type = "response"),
p_win_total = p_win_first * p_first_in + p_win_second * (1 - p_first_in)
)
# --- Find optimal serve speed ---
optimal_row <- grid_data %>% filter(p_win_total == max(p_win_total)) %>% slice(1)
ggplot(grid_data, aes(x = Speed_MPH, y = p_win_total)) +
geom_line(size = 1.2, color = "blue") +
geom_point(data = optimal_row, aes(x = Speed_MPH, y = p_win_total), color = "red", size = 3) +
geom_text(
data = optimal_row,
aes(x = Speed_MPH, y = p_win_total, label = sprintf("Optimal: %.0f MPH", Speed_MPH)),
vjust = -1.2, hjust = 0.5, size = 4, color = "red"
) +
labs(
title = "Serve Speed vs. Overall Point Win Probability",
x = "Serve Speed (MPH)",
y = "P(win)",
caption = "Holding serve placement, importance, df_pct, and opponent quality constant"
) +
theme_minimal()
# --- Create speed range and compute z-scores ---
speed_seq <- seq(80, 145, by = 1)
speed_mean <- mean(df$Speed_MPH, na.rm = TRUE)
speed_sd <- sd(df$Speed_MPH, na.rm = TRUE)
speed_z <- (speed_seq - speed_mean) / speed_sd
# --- Construct data for prediction ---
grid_data <- tibble(
Speed_MPH = speed_seq,
speed_ratio_z = (speed_seq / mean(df$Speed_MPH, na.rm = TRUE) - 1),  # use ratio to player average
importance_z = median_vals$importance_z,
df_pct_server_z = median_vals$df_pct_server_z,
p_server_beats_returner_z = median_vals$p_server_beats_returner_z,
ServeWidth = mode_width,
ServeDepth = mode_depth
)
# --- Predict win probabilities ---
p_first_in <- 0.6481901
grid_data <- grid_data %>%
mutate(
p_win_first = predict(model_first, newdata = ., type = "response"),
p_win_second = predict(model_second, newdata = ., type = "response"),
p_win_total = p_win_first * p_first_in + p_win_second * (1 - p_first_in)
)
# --- Find optimal serve speed ---
optimal_row <- grid_data %>% filter(p_win_total == max(p_win_total)) %>% slice(1)
# --- Plot ---
library(ggplot2)
ggplot(grid_data, aes(x = Speed_MPH, y = p_win_total)) +
geom_line(size = 1.2, color = "blue") +
geom_point(data = optimal_row, aes(x = Speed_MPH, y = p_win_total), color = "red", size = 3) +
geom_text(
data = optimal_row,
aes(x = Speed_MPH, y = p_win_total, label = sprintf("Optimal: %.0f MPH", Speed_MPH)),
vjust = -1.2, hjust = 0.5, size = 4, color = "red"
) +
labs(
title = "Serve Speed vs. Overall Point Win Probability",
x = "Serve Speed (MPH)",
y = "P(win)",
caption = "Holding serve placement, importance, df_pct, and opponent quality constant"
) +
theme_minimal()
